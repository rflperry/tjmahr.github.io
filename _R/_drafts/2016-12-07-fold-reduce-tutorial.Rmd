---
title: Draft post (2016-12-07)
excerpt: ''
tags: ''
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

My favorite feature of R is its version of functional programming. Given some
data cleaning or processing problem, I can pretty quickly build up a miniature
language to help me tackle that problem. It makes me feel like a wizard from the
cover of _Structure and Interpretation of Computer Programming_. In fact, I
chased that wizarding high: I got _SICP_ for my birthday a couple years ago and 
regularly read about functional programming in JavaScript so I can translate 
those lessons in R. My affinity for FP is this site is called "Higher Order Functions".

Thus, it's not much of a surprise that I evangelized about the higher-order
function `Reduce()` on a recent [StackOverflow answer](http://stackoverflow.com/a/40872014/1084259). There are three classic higher-order functions---`Map()`, `Filter()`, and what's called `Reduce()` in R but called _fold_ more generally. 

`Reduce()` applies a binary function over every pair of items in a vector. 

For example, ``Reduce(`+`, xs)`` computes the sum of values in vector. For an
infix-function like `+`, we can roughly think of it as replacing each `,` with a
`+`.

```{r}
Reduce(`+`, c(1, 2, 3, 4, 5, 6))

# What Reduce is doing here, basically
((((((1) + 2) + 3) + 4) + 5) + 6)
```

My first use case of using `Reduce()` was in 2012 as a naive way to combine many
different csvs/data-frames into one data-frame. Suppose we have a list of
data-frames, reflecting the contents of different csv files.

```{r, echo = FALSE}
# Shhh... let's pretend like I loaded three csvs into a list.
iris2 <- iris
iris2[1:2] <- NULL
flower_dfs <- split(iris2, iris$Species)
names(flower_dfs) <- paste0("data/", names(flower_dfs), ".csv")
```

```{r}
str(flower_dfs)
```

Aaah, how can I put these all into a single data-frame? Nowadays, I'd use 
`dpylr::bind_rows()` or apply the original csv-loading function with 
`purrr::map_df()`. But in 2012, those didn't exist. (`plyr::rbind.fill()` did,
but plyr wasn't on my radar yet.)

I know how to solve the problem individual combinations of data-frames with
`rbind()`, but this doesn't work on the whole list.

```{r}
first_two <- rbind(flower_dfs[[1]], flower_dfs[[2]])
str(first_two)

# Argh
rbind(flower_dfs)
```

But if I know how to use a function to fold two things into one thing, then I 
can use `Reduce()` to fold many of them into one thing. **Read that sentence
again** because it's the big idea behind `Reduce()`. Figure out how to combine
two of the things and `Reduce()` can combine all of the things.

```{r}
all_of_them <- Reduce(rbind, flower_dfs)
str(all_of_them)
```

This problem, having to flatten a list of dozens of csvs into a single 
data-frame, was my first use case for using Reduce(). Also, it is **not the best
way to solve this problem in base R**. (The main argument to `rbind()` is `...`;
that is, a variable number of data-frames. We should use `do.call(rbind,
flowers_df)` which calls a function but gets the arguments from a list.)









If we set `accumulate = TRUE`, we get a rolling/cumulative sum.

```{r}
# Keep each intermediate sum
Reduce(`+`, 1:6, accumulate = TRUE)
#> [1]  1  3  6 10 15 21


```



The purrr package smartly separates these two behaviors into different functions: `reduce()` and `accumulate()`.

We can use `Reduce()` to implement the carry-over/scaling function. First, define a function that works on a pair of values, then use `Reduce()` to perform a rolling version of it.

```{r}
rolling_scale <- function(xs, scale_factor) {
  scale_pair <- function(x1, x2) x2 + scale_factor * x1
  Reduce(scale_pair, xs, accumulate = TRUE)
}

rolling_scale(c(4, 5, 0), .5)
#> [1] 4.0 7.0 3.5
```




Now, we can use dplyr and apply this rolling function to each indicator group.

```{r}
library(dplyr)

raw <- data.frame(
  ColumnA = c(1, 0, 0, 4, 5, 0, 4, 0, 2), 
  Indicator = rep(x = 1:3, each = 3), 
  Time = 1:3)

raw %>% 
  group_by(Indicator) %>% 
  mutate(ColumnB = rolling_scale(ColumnA, .5)) %>% 
  ungroup()
#> # A tibble: 9 Ã— 4
#>   ColumnA Indicator  Time ColumnB
#>     <dbl>     <int> <int>   <dbl>
#> 1       1         1     1    1.00
#> 2       0         1     2    0.50
#> 3       0         1     3    0.25
#> 4       4         2     1    4.00
#> 5       5         2     2    7.00
#> 6       0         2     3    3.50
#> 7       4         3     1    4.00
#> 8       0         3     2    2.00
#> 9       2         3     3    3.00
```








Reduce, also  frequently called _fold_, is one of the three classic high-order functions alongside _map_ and _filter_.

There are three classic higher-order functions:

1. _map_: c(a, b, c) becomes c(f(a), f(b), f(c))
(apply a function to each element in a list), _fold_ a.k.a. _reduce_ (apply a function to every), and filter.
