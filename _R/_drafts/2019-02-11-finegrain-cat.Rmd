---
title: Draft post (2019-02-11)
excerpt: ''
tags: ''
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


In Septemer, I started a job as a data scientist for an NIH project studying how
children with cerebral palsy develop speech, language and communication.
My title says scientist, but I say data scientist because I still do all my work
in RStudio.

In this post, I walk through the code I used to make a nice diagram explaining
how a logistic growth curve works.

We're talking about time series of repeated measurements.

We're talking

Children can be hard to understand; they are learning to talk after all. This
problem is compounded for children with cerebral palsy, because these kids will
often speech-motor impairments. My current project is a model of how
intelligibility---the probability that a listener understands what a child
says---develops from age 3 to age 8. 

We expected children 
to follow a certain developmental trajectory: Begin at zero intelligibility, 
show a period of accelerating then decelerating growth, and finally plateau at 
some mature level of ability. This pattern of growth can be modeled using a logistic 
growth curve using three parameters: an asymptote, a midpoint when growth is 
steepest, and a scale which sets the slope of the curve. 
Now my job for a recent abstract submission was to briefly illustrate what these curves look like but not let the curve




This curve is 
flexible enough to capture many patterns—for example, sudden growth (sharp 
slope), delay (later midpoint), or no change at all (low asymptote)—so these 
parameters provide a way to estimate group-level and individual differences 
in developmental trajectories.



First, here's a helper I've been using to study these curves. It 


```{r}
library(tidyverse)

# Generate a single curve
generate_one_curve <- function(time = -10:10, mid = NULL,
                           asymptote = NULL, scale = NULL) {
  # If no value is given, draw one from a distribution
  mid <- mid %||% rnorm(1, median(time), IQR(time) / 5)
  asymptote <- asymptote %||% rbeta(1, 2, 1)
  scale <- scale %||% rnorm(1, .1, .05)

  y <- asymptote / (1 + exp((mid - time) * scale))

  tibble(
    time = time,
    proportion = y,
    asymptote = asymptote,
    scale = scale,
    min_proportion = min(y),
    mid = mid)
}

generate_curves <- function(n = 1, ...) {
  # this function ignores the argument and just runs the function on the dots
  make_one <- function(x) {
    generate_one_curve(...)
  }

  purrr::map_df(
    seq_len(n),
    make_one,
    .id = "sample")
}

library(tidyverse)
generate_curves(40, time = 0:100) %>%
  ggplot() +
  aes(x = time, y = proportion, group = sample) +
  geom_line()

generate_curves(100, time = 0:100, mid = 50, scale = .5) %>%
  ggplot() +
    aes(x = time, y = proportion, group = sample) +
    geom_line(alpha = .5)

generate_curves(100, time = 0:100, asymptote = .95, scale = .5) %>%
  ggplot() +
    aes(x = time, y = proportion, group = sample) +
    geom_line(alpha = .5)

generate_curves(100, time = 0:100, asymptote = .95, mid = 50) %>%
  ggplot() +
  aes(x = time, y = proportion, group = sample) +
  geom_line(alpha = .5)


```





















































```{r}

```


My textbook reference on these kinds of models is Davidian and Giltinan. I've
more thumbed through it than studied it very closely, because a lot of the text
seems to be how to estimate these things and I'm letting Bayes handle those
details.


To prepare this demo, I had to work through the Bayesian workflow from scratch on a new dataset. brms requires priors, but I do not want to peek at the data. On the other hand, I don't need to give the model some information to help it out. Thus, I weakly informative priors.

First, I peeked at the range of the data.

```{r}
skimr::skim(d)
```

Then I devised priors that would hit these ranges.



```{r}
library(tidyverse)
library(rstan)
library(brms)
library(tidybayes)

# The next few lines just follow advice from RStan

options(mc.cores = 4)
rstan_options(auto_write = TRUE)
Sys.setenv(LOCAL_CPPFLAGS = '-march=native')

# For execution on a local, multicore CPU with excess RAM we recommend calling
#   options(mc.cores = parallel::detectCores()).
#
# To avoid recompilation of unchanged Stan programs, we recommend calling
#   rstan_options(auto_write = TRUE)
#
# For improved execution time, we recommend calling
#   Sys.setenv(LOCAL_CPPFLAGS = '-march=native')
# although this causes Stan to throw an error on a few processors.
formula_beta2 <- bf(
  weight ~ asym * inv(1 + exp((mid - day) * exp(scale))),
  # asym ~ 1 + trt + (1 | ID | plot),
  asym ~ 1 +  (1 | ID | plot),
  mid ~ 1 +  (1 | ID | plot),
  scale ~ 1 + (1 | ID | plot),
  nl = TRUE)

# Prior for the individual children's asymptotes in NSMI group
hist(rnorm(
  1000,
  mean = rnorm(1000, 20, 10),
  sd = abs(rnorm(1000, 0, 10)))
)

plot_priors <- function(x, n, asymptote = rbeta(n, 10, 20),
                        midpoint = rnorm(n, 0, 1),
                        scale = abs(rnorm(n, .1, .025))) {

  # stash sampling statements
  asymptote_expr <- enexpr(asymptote)
  midpoint_expr <- enexpr(midpoint)
  scale_expr <- enexpr(scale)

  # evaluate sampling statements with n supplied
  samples <- list(
    sample = seq_len(n),
    asymptote = rlang::eval_tidy(asymptote_expr, list(n = n)),
    midpoint = rlang::eval_tidy(midpoint_expr, list(n = n)),
    scale = rlang::eval_tidy(scale_expr, list(n = n)))

  # compute the nonlinear curve for each sample
  xs <- seq(min(x), max(x), length.out = 80)

  data <- samples %>%
    pmap_dfr(
      function(sample, asymptote, midpoint, scale) {
        tibble::tibble(
          xs = xs,
          ys = asymptote / (1 + exp((midpoint - xs) / scale)),
          sample = sample)
      })

  p <- ggplot(data) +
    aes(xs, ys) +
    geom_line(aes(group = sample))

  print(p)
  invisible(data)
}

plot_priors(d$day, n = 100, asymptote = rnorm(n, 20, 10), midpoint = rnorm(n, 40, 10), scale = rnorm(n, 8, 3))

prior_fixef <- c(
  prior(normal(20, 5), nlpar = "asym", coef = "Intercept"),
  prior(normal(40, 10), nlpar = "mid", coef = "Intercept"),
  prior(normal(8, 3), nlpar = "scale", coef = "Intercept"),
  prior(exponential(1), class = "sigma")
)

prior_ranef <- c(
  prior(exponential(.2), class = "sd", nlpar = "asym"),
  prior(exponential(.2), class = "sd", nlpar = "mid"),
  prior(exponential(1), class = "sd", nlpar = "scale"),
  prior(lkj_corr_cholesky(2), class = "L"))

d <- nlmrmd::soybean
fit_beta <- brm(
  formula_beta2,
  data = d,
  prior = c(prior_fixef, prior_ranef),
  iter = 2000,
  chains = 4,
  control = list(adapt_delta = 0.90, max_treedepth = 15))
fit_beta

d

ggplot(d) + 
  aes(x = day, y = lwt, color = factor(trt)) + 
  geom_point() + 
  geom_line(aes(group = plot)) + 
  facet_wrap("trt")

fit_draw <- fit_beta 

# d %>%
#   tidyr::expand(
#     day = seq(min(day), max(day), length.out = 80),
#     nesting(plot, trt)) %>%
#   tidybayes::add_fitted_draws(
#     fit_draw,
#     n = 100) %>%
#   ggplot() +
#     aes(x = day, y = .value, color = factor(trt)) +
#     stat_summary(fun.data = median_hdci) +
#     geom_point(aes(y = lwt), data = d ) +
#     facet_wrap("trt")

intels <- d %>%
  distinct(day, trt, lwt)

summary <- d %>%
  tidyr::expand(
    day = seq(min(day), max(day), length.out = 80),
    nesting(plot, year, phenotype)) %>%
  tidybayes::add_fitted_draws(fit_draw, n = 100) %>%
  ungroup()


summary %>% 
  tjmisc::sample_n_of(20, .draw) %>%
  tjmisc::sample_n_of(9, plot) %>% 
  ggplot() +
    aes(x = day, y = .value) +
    geom_line(
      aes(y = .value, group = .draw),
      color = "#B6297B",
      alpha = .2) +
  geom_point(
    aes(y = weight),
    data = . %>% distinct(plot) %>% inner_join(d)) +
  facet_wrap("plot")
tjmisc::ggpreview()
```



```{r}
library(tidyverse)

# Generate a single curve
generate_one_curve <- function(time = -10:10, mid = NULL,
                           asymptote = NULL, scale = NULL) {
  # If no value is given, draw one from a distribution
  mid <- mid %||% rnorm(1, 0, 3)
  asymptote <- asymptote %||% rbeta(1, 2, 1)
  scale <- scale %||% (1 / rnorm(1, 10, 4))

  y <- asymptote / (1 + exp((mid - time) * scale))

  tibble(
    time = time,
    proportion = y,
    asymptote = asymptote,
    scale = scale,
    min_proportion = min(y),
    mid = mid)
}

generate_curves <- function(n = 1, ...) {
  # this function ignores the argument and just runs the function on the dots
  make_one <- function(x) {
    generate_one_curve(...)
  }

  purrr::map_df(
    seq_len(n),
    make_one,
    .id = "sample")
}

library(tidyverse)
generate_curves(40) %>%
  ggplot() +
  aes(x = time, y = proportion, group = sample) +
  geom_line()

generate_curves(100,  mid = 0, scale = .5) %>%
  ggplot() +
    aes(x = time, y = proportion, group = sample) +
    geom_line(alpha = .5)

generate_curves(100, asymptote = .95, scale = .5) %>%
  ggplot() +
    aes(x = time, y = proportion, group = sample) +
    geom_line(alpha = .5)

generate_curves(100, asymptote = .95, mid = 0) %>%
  ggplot() +
  aes(x = time, y = proportion, group = sample) +
  geom_line(alpha = .5)


```

